{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c1e1cd",
   "metadata": {},
   "source": [
    "# Exploration of using the Modified Hazardous Situation ODP\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b91845",
   "metadata": {},
   "source": [
    "A modified Hazardous Situation ODP (Ontology Design Pattern) is a refined version of the existing pattern that enhances its ability to support risk assessment and mitigation planning. This modification focuses on breaking down aspects of exposure to a hazard into individual components, allowing for a more granular understanding of the impact on different objects and people.\n",
    "\n",
    "Here's a more detailed explanation:\n",
    "Existing Hazardous Situation ODP:\n",
    "The original pattern effectively addresses core competency questions related to hazard exposure.\n",
    "\n",
    "The modified pattern expands on the original by:\n",
    "- Breaking down exposure components: This allows for a more precise analysis of how different objects and individuals are affected by the same hazard. \n",
    "- Supporting risk assessment and mitigation: The modified pattern enables a more comprehensive approach to identifying and addressing potential hazards. \n",
    "- Considering individual susceptibility: The modification acknowledges that different entities (objects, people, etc.) may be impacted differently by the same hazard due to their unique characteristics. \n",
    "\n",
    "Key Benefit:\n",
    "- The modified pattern helps in identifying and addressing potential hazards more effectively by considering the specific context of each situation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7edda",
   "metadata": {},
   "source": [
    "![MH-ODP](./hazard/hazard-odp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432b448",
   "metadata": {},
   "source": [
    "Turning the Hazardous‑Situation stack into a “conscience loop”\n",
    "\n",
    "(all labels correspond to files or modules you already have in CogitareLink)\n",
    "\n",
    "┌────────────── sensors / world model ─────────────┐\n",
    "│  depth cam, IMU, PLC tags …                      │\n",
    "└──────┬────────────────────────────────────────────┘\n",
    "       │ 1. fresh state triples  (Layer 3 data.jsonld)\n",
    "┌──────▼───────────────┐\n",
    "│  LLM Planner         │  (Chain‑of‑Thought + skill tools)\n",
    "│  • decomposes goal    │\n",
    "│  • proposes plan P    │  → JSON‑LD action graph\n",
    "└──────┬───────────────┘\n",
    "       │ 2. *pre‑flight conscience check*\n",
    "┌──────▼───────────────────────────┐\n",
    "│  CogitareLink sandbox            │  (single tool: `reason_over`)\n",
    "│  pass A – SHACL                  │\n",
    "│    uses `haz-shapes.ttl`         │  ➜ flag risk, emit violation\n",
    "│  pass B – EYE (optional)         │\n",
    "│    uses `haz-logic.n3`           │  ➜ obligations, CTD fixes\n",
    "└──────┬───────────────────────────┘\n",
    "       │ 3. NL summary + prov IRI\n",
    "┌──────▼─────────────────┐\n",
    "│  LLM Moral Governor    │\n",
    "│  • reads violations / duties\n",
    "│  • decides:            │\n",
    "│      a) reject plan           (risk un‑mitigated)  \n",
    "│      b) revise plan           (insert mitigating steps)  \n",
    "│      c) approve & explain     (compliant)\n",
    "└──────┬─────────────────┘\n",
    "       │ 4. approved plan P′\n",
    "┌──────▼──────────┐\n",
    "│  Low‑level exec │  (controllers, ROS2, PLC)\n",
    "└─────────────────┘\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "1.  What the “conscience” actually does\n",
    "\n",
    "Stage\tConcrete check / synthesis\tBacking artifact\n",
    "Detect\t“Any participant’s exposure > susceptibility?”\tRiskEvalShape (SHACL rule)\n",
    "Judge\tMap violation → obligation (CTD)\tDeonticHazardRules (N3)\n",
    "Explain\tProduce NL sentence:  \\n“Plan would expose Pump‑A to 150 psi (> 120 psi limit).  Obligation: throttle flow or abort.”\tsummary from reason_over, plus prov:Activity proof\n",
    "Guide\tFeed obligation back to planner (insert_mitigation() function or a fresh tool call)\thandled by LLM Governor\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "2.  Wiring in code (pseudo‑Python)\n",
    "\n",
    "def conscience_check(plan_jsonld: str) -> bool:\n",
    "    # 1. Run SHACL\n",
    "    res1 = reason_over(jsonld=plan_jsonld,\n",
    "                       shapes_turtle=HAZ_SHAPE_TTL)\n",
    "    if not res1['violations']:\n",
    "        return True                     # safe, no risk\n",
    "\n",
    "    # 2. Run EYE for CTD duties\n",
    "    res2 = reason_over(jsonld=plan_jsonld,\n",
    "                       n3_rules=HAZ_N3)\n",
    "    duties = res2['derived'].filter(dl.obliges)\n",
    "\n",
    "    # 3. Decide\n",
    "    if duties:\n",
    "        planner.insert_steps(duties)    # revise plan\n",
    "        return conscience_check(planner.current_plan())\n",
    "    else:\n",
    "        return False                    # reject – no remedy\n",
    "\n",
    "One recursive call is usually enough because CTD rules introduce an explicit mitigation step.\n",
    "\n",
    "⸻\n",
    "\n",
    "3.  Fast‑path vs. slow‑path\n",
    "\t•\tFast‑path (no risk): only SHACL fires → single tool call, < 10 ms.\n",
    "\t•\tSlow‑path (risk): SHACL + EYE + 1 plan rewrite → ~40 ms on a laptop.\n",
    "This fits well inside a 10 Hz control‑loop envelope for mobile robots and is trivial latency for industrial arms that run at 250 ms cycles.\n",
    "\n",
    "⸻\n",
    "\n",
    "4.  Why the split SHACL → EYE matters\n",
    "\n",
    "Reason\tImpact on embodied agent\n",
    "Streaming‑friendly\tSHACL validation can run incrementally as sensor facts arrive; no need to wait for full plan.\n",
    "Explain‑first\tViolations come with human‑readable messages, so the robot can speak “Potential overpressure detected.” before deciding on mitigation.\n",
    "Formality when needed\tEYE only spins up when real conflict appears, avoiding proof‑engine overhead on every cycle.\n",
    "CTD logic\tLets the system repair a risky plan instead of blindly cancelling — key for mission continuity.\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "5.  Example dialogue loop\n",
    "\n",
    "User: “Robot, swap the reactor filters.”\n",
    "Robot: “Hold on. Performing risk check…”\n",
    "Conscience output: Violation: Exposure to corrosive gas > threshold. Obligation: wear viton seal gloves.\n",
    "Robot: “I must equip viton gloves first. Proceed?”\n",
    "User: “Yes.”\n",
    "Robot: executes revised plan with mitigation step.\n",
    "\n",
    "All reasoning‑layer provenance is logged; if auditors ask why the robot insisted on gloves, you point them to the prov:Activity proof containing the violated shape and fired CTD rule.\n",
    "\n",
    "⸻\n",
    "\n",
    "6.  Extensible beyond hazards\n",
    "\n",
    "Identical pattern supports:\n",
    "\t•\tPrivacy conscience: SHACL detects PII leakage → N3 obliges anonymisation.\n",
    "\t•\tEthical alignment: SHACL detects human discomfort cues → N3 imposes obligation to re‑phrase utterance.\n",
    "\t•\tEnergy budget: SHACL flags battery below threshold → N3 obliges return‑to‑dock.\n",
    "\n",
    "Swap in different Layer 2a/2b bundles; the micro‑kernel stays untouched.\n",
    "\n",
    "⸻\n",
    "\n",
    "Bottom line\n",
    "\n",
    "By sandwiching fast, declarative SHACL risk detection with expressive N3 deontic rules—and looping the result back to the LLM planner—you get a lightweight conscience that:\n",
    "\t1.\tCatches hazards before action execution.\n",
    "\t2.\tOffers concrete, plan‑level remedies (CTD).\n",
    "\t3.\tMaintains a provable audit trail.\n",
    "\n",
    "All with nothing more exotic than two reason_over calls and a small governing callback around your existing planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7547cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ░░ 2. Imports ░░\n",
    "from cosette import *\n",
    "# Apply the patches first to extend reason_over with n3_rules support\n",
    "import patch_reason_sandbox\n",
    "import patch_reason_tool\n",
    "from cogitarelink.reason.sandbox import reason_over\n",
    "from cogitarelink.core.graph import GraphManager\n",
    "from pathlib import Path, PurePosixPath\n",
    "import json, rdflib as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ed9480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ░░ 3. Load artefacts ░░\n",
    "DATA_DIR = Path(\"hazard\")\n",
    "scenario  = (DATA_DIR / \"scenario.jsonld\").read_text()\n",
    "shapes    = (DATA_DIR / \"haz-shapes.ttl\").read_text()\n",
    "n3_rules  = (DATA_DIR / \"haz-logic.n3\").read_text()\n",
    "\n",
    "gm = GraphManager()                     # persistent, in‑memory for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3910eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ░░ 4. Wrap reason_over for Cosette ░░\n",
    "def shacl_check(jsonld:str)->str:\n",
    "    # reason_over returns a tuple of (patch_jsonld, nl_summary)\n",
    "    patch, summary = reason_over(jsonld=jsonld, shapes_turtle=shapes)\n",
    "    if patch:\n",
    "        # Convert JSON-LD to N-Quads\n",
    "        ds = R.Dataset()\n",
    "        ds.parse(data=patch, format=\"json-ld\")\n",
    "        nquads = ds.serialize(format=\"nquads\")\n",
    "        gm.ingest_nquads(nquads, graph_id=\"patch\")\n",
    "    return summary\n",
    "\n",
    "def eye_check(jsonld:str)->str:\n",
    "    # reason_over returns a tuple of (patch_jsonld, nl_summary)\n",
    "    patch, summary = reason_over(jsonld=jsonld, n3_rules=n3_rules)\n",
    "    if patch:\n",
    "        # Convert JSON-LD to N-Quads\n",
    "        ds = R.Dataset()\n",
    "        ds.parse(data=patch, format=\"json-ld\")\n",
    "        nquads = ds.serialize(format=\"nquads\")\n",
    "        gm.ingest_nquads(nquads, graph_id=\"patch\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f7b603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('o1-preview',\n",
       " 'o1-mini',\n",
       " 'gpt-4o',\n",
       " 'gpt-4o-mini',\n",
       " 'gpt-4-turbo',\n",
       " 'gpt-4',\n",
       " 'gpt-4-32k',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-instruct')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5e8daf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scenario with fixed context path...\n",
      "\n",
      "Running demo:\n",
      "TOOL CALL: [ChatCompletionMessageToolCall(id='call_zd0Kje6lJoOPeBBzhILUeYz5', function=Function(arguments='{\"plan_jsonld\": \"{\\\\n  \\\\\"@context\\\\\": \\\\\"hazard/haz.context.jsonld\\\\\",\\\\n  \\\\\"@id\\\\\": \\\\\"ex:scenario_1\\\\\",\\\\n  \\\\\"@type\\\\\": \\\\\"HazardousSituation\\\\\",\\\\n  \\\\\"hasShape\\\\\": \\\\\"ex:RiskEvalShape\\\\\",\\\\n  \\\\\"hasN3Rule\\\\\": \\\\\"ex:DeonticHazardRules\\\\\",\\\\n  \\\\\"hasParticipant\\\\\": {\\\\n    \\\\\"@id\\\\\": \\\\\"ex:Tank7\\\\\",\\\\n    \\\\\"@type\\\\\": \\\\\"Object\\\\\",\\\\n    \\\\\"exposedTo\\\\\": {\\\\n      \\\\\"@id\\\\\": \\\\\"ex:Exposure_Tank7\\\\\",\\\\n      \\\\\"@type\\\\\": \\\\\"Exposure\\\\\",\\\\n      \\\\\"hasAmount\\\\\": 150.0\\\\n    },\\\\n    \\\\\"hasSusceptibility\\\\\": {\\\\n      \\\\\"@id\\\\\": \\\\\"ex:Suscept_Tank7\\\\\",\\\\n      \\\\\"@type\\\\\": \\\\\"Susceptibility\\\\\",\\\\n      \\\\\"toExposure\\\\\": {\\\\n        \\\\\"@id\\\\\": \\\\\"ex:Exposure_Tank7\\\\\"\\\\n      },\\\\n      \\\\\"hasAmount\\\\\": 120.0\\\\n    }\\\\n  },\\\\n  \\\\\"participantIn\\\\\": {\\\\n    \\\\\"@id\\\\\": \\\\\"ex:event_1\\\\\",\\\\n    \\\\\"@type\\\\\": \\\\\"HazardousEvent\\\\\",\\\\n    \\\\\"description\\\\\": \\\\\"Robot will open Tank\\\\\\\\u20117 lid and inspect filters\\\\\"\\\\n  }\\\\n}\"}', name='shacl_validate'), type='function'), ChatCompletionMessageToolCall(id='call_jncnx7dRg3axMJupakSk40fo', function=Function(arguments='{\"plan_jsonld\": \"{\\\\n  \\\\\"@context\\\\\": \\\\\"hazard/haz.context.jsonld\\\\\",\\\\n  \\\\\"@id\\\\\": \\\\\"ex:scenario_1\\\\\",\\\\n  \\\\\"@type\\\\\": \\\\\"HazardousSituation\\\\\",\\\\n  \\\\\"hasShape\\\\\": \\\\\"ex:RiskEvalShape\\\\\",\\\\n  \\\\\"hasN3Rule\\\\\": \\\\\"ex:DeonticHazardRules\\\\\",\\\\n  \\\\\"hasParticipant\\\\\": {\\\\n    \\\\\"@id\\\\\": \\\\\"ex:Tank7\\\\\",\\\\n    \\\\\"@type\\\\\": \\\\\"Object\\\\\",\\\\n    \\\\\"exposedTo\\\\\": {\\\\n      \\\\\"@id\\\\\": \\\\\"ex:Exposure_Tank7\\\\\",\\\\n      \\\\\"@type\\\\\": \\\\\"Exposure\\\\\",\\\\n      \\\\\"hasAmount\\\\\": 150.0\\\\n    },\\\\n    \\\\\"hasSusceptibility\\\\\": {\\\\n      \\\\\"@id\\\\\": \\\\\"ex:Suscept_Tank7\\\\\",\\\\n      \\\\\"@type\\\\\": \\\\\"Susceptibility\\\\\",\\\\n      \\\\\"toExposure\\\\\": {\\\\n        \\\\\"@id\\\\\": \\\\\"ex:Exposure_Tank7\\\\\"\\\\n      },\\\\n      \\\\\"hasAmount\\\\\": 120.0\\\\n    }\\\\n  },\\\\n  \\\\\"participantIn\\\\\": {\\\\n    \\\\\"@id\\\\\": \\\\\"ex:event_1\\\\\",\\\\n    \\\\\"@type\\\\\": \\\\\"HazardousEvent\\\\\",\\\\n    \\\\\"description\\\\\": \\\\\"Robot will open Tank\\\\\\\\u20117 lid and inspect filters\\\\\"\\\\n  }\\\\n}\"}', name='eye_reason'), type='function')]\n",
      "TOOL CALL: The review of your plan indicated that there are no specific SHACL violations, which suggests that the plan conforms to the defined constraints and there are no immediate hazards based on the constraints evaluated.\n",
      "\n",
      "Additionally, when assessing the plan with the EYE reasoner, no new obligations or issues were derived from the N3 rules. This indicates that there were no additional intricacies or implicit obligations detected, apart from those directly suggested or implied in the initial context.\n",
      "\n",
      "In summary, there are no overt concerns or obligations that arise from this plan with the given inputs and rules.\n",
      "\n",
      "\n",
      "=== FINAL RESULT ===\n",
      "<IPython.core.display.Markdown object>\n"
     ]
    }
   ],
   "source": [
    "# ░░ 5. Expose symbolic conscience as a Cosette tool and demo LLM tool use ░░\n",
    "from typing import Literal\n",
    "import json\n",
    "import os\n",
    "\n",
    "model = models[2]\n",
    "\n",
    "# Fix context path in the scenario JSON-LD\n",
    "scenario_json = json.loads(scenario)\n",
    "scenario_json[\"@context\"] = str(DATA_DIR / \"haz.context.jsonld\")\n",
    "scenario_fixed = json.dumps(scenario_json, indent=2)\n",
    "\n",
    "def shacl_validate(plan_jsonld: str) -> str:\n",
    "    \"\"\"\n",
    "    Validates a plan against SHACL shapes to identify constraint violations.\n",
    "    \n",
    "    plan_jsonld: The plan as a JSON-LD string.\n",
    "    Returns a human-readable summary of violations.\n",
    "    \"\"\"\n",
    "    return shacl_check(plan_jsonld)\n",
    "\n",
    "def eye_reason(plan_jsonld: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies Notation3 rules to a plan using EYE reasoner to derive obligations.\n",
    "    \n",
    "    plan_jsonld: The plan as a JSON-LD string.\n",
    "    Returns a human-readable summary of derived obligations.\n",
    "    \"\"\"\n",
    "    return eye_check(plan_jsonld)\n",
    "\n",
    "chat = Chat(\n",
    "    model,\n",
    "    sp=\"You are a conscientious planner. First use 'shacl_validate' to check for risks. If violations are found, use 'eye_reason' to determine obligations.\",\n",
    "    tools=[shacl_validate, eye_reason]\n",
    ")\n",
    "\n",
    "print(\"Using scenario with fixed context path...\")\n",
    "# Not printing the full scenario for clarity\n",
    "\n",
    "print(\"\\nRunning demo:\")\n",
    "# Use toolloop instead of direct call for better handling\n",
    "result = chat.toolloop(\n",
    "    f\"Please review this plan for hazards and explain what concerns exist and what obligations arise:\\n{scenario_fixed}\",\n",
    "    trace_func=lambda r: print(f\"TOOL CALL: {r.choices[0].message.content if r.choices[0].message.content else r.choices[0].message.tool_calls}\")\n",
    ")\n",
    "\n",
    "print(\"\\n\\n=== FINAL RESULT ===\")\n",
    "from cosette import contents, wrap_latex\n",
    "print(wrap_latex(contents(result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
